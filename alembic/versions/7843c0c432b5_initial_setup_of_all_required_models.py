"""initial setup of all required models

Revision ID: 7843c0c432b5
Revises: 
Create Date: 2024-11-11 20:26:23.323599

"""

from typing import Sequence, Union

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "7843c0c432b5"
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "jobs",
        sa.Column(
            "id", sa.UUID(), server_default=sa.text("gen_random_uuid()"), nullable=False
        ),
        sa.Column(
            "created_at", sa.DateTime(), server_default=sa.text("now()"), nullable=True
        ),
        sa.Column("finished", sa.DateTime(), nullable=True),
        sa.Column(
            "status",
            postgresql.ENUM("created", "running", "failed", name="status"),
            nullable=False,
        ),
        sa.Column("depth", sa.Integer(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index("crawling_job_status", "jobs", ["status"], unique=False)
    op.create_table(
        "targets",
        sa.Column(
            "id",
            sa.UUID(),
            server_default=sa.text("gen_random_uuid()"),
            nullable=False,
            comment="this will be used as filename",
        ),
        sa.Column("crawling_job_id", sa.UUID(), nullable=True),
        sa.Column(
            "created_at", sa.DateTime(), server_default=sa.text("now()"), nullable=True
        ),
        sa.Column(
            "website",
            sa.String(length=256),
            nullable=False,
            comment="this is the root URL",
        ),
        sa.Column("s3_bucket", sa.String(length=256), nullable=True),
        sa.Column("s3_location", sa.String(length=256), nullable=True),
        sa.Column("filesystem_location", sa.String(length=256), nullable=True),
        sa.Column(
            "website_metadata",
            sa.JSON(),
            nullable=True,
            comment="example location usage for dun number or any other valuable information",
        ),
        sa.Column("count_pdf_pages", sa.Integer(), nullable=True),
        sa.Column("count_html_pages", sa.Integer(), nullable=True),
        sa.Column("largest_pdf_size", sa.Integer(), nullable=True),
        sa.Column("largest_pdf_link", sa.String(length=256), nullable=True),
        sa.ForeignKeyConstraint(
            ["crawling_job_id"],
            ["jobs.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "pages",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("target_id", sa.UUID(), nullable=True),
        sa.Column(
            "page_type",
            postgresql.ENUM("HTML", "PDF", name="page_types"),
            nullable=False,
        ),
        sa.Column(
            "page_content_type",
            postgresql.ENUM(
                "TEXT",
                "TEXT/unicode",
                "UNKNOWN",
                "HTML/unparsed",
                "XML/unparsed",
                "JSON/unparsed",
                name="page_content_types",
            ),
            nullable=False,
        ),
        sa.Column(
            "website",
            sa.String(length=256),
            nullable=False,
            comment="full URL of the page which was scraped",
        ),
        sa.Column("has_title", sa.Boolean(), nullable=False),
        sa.Column("has_content", sa.Boolean(), nullable=False),
        sa.ForeignKeyConstraint(
            ["target_id"],
            ["targets.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("pages")
    op.drop_table("targets")
    op.drop_index("crawling_job_status", table_name="jobs")
    op.drop_table("jobs")
    # ### end Alembic commands ###
